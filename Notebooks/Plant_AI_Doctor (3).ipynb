{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic Data Generation\n",
        "\n",
        "We conducted an initial qualitative exploration of synthetic data generation\n",
        "for chemical leaf damage using generative AI models.\n",
        "\n",
        "Text-to-image generation showed a strong tendency toward disease-like patterns,\n",
        "while image-to-image generation provided better control and produced more\n",
        "chemical stress–like appearances.\n",
        "\n",
        "At this stage, synthetic data was used for qualitative analysis only and was\n",
        "not integrated into model training. Further use of synthetic data is planned.\n"
      ],
      "metadata": {
        "id": "pE6-TfO9vXdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "03Af9ANFt86G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2b28cc-a0af-429d-94b0-1484b5bf9e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open Plant-AI-Doctor.zip, Plant-AI-Doctor.zip.zip or Plant-AI-Doctor.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Plant-AI-Doctor.zip"
      ],
      "metadata": {
        "id": "RpHB2ib1vShH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA864788_cUS",
        "outputId": "c219f899-5ae1-428b-ffe4-687664b2166e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Plant-AI-Doctor\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU6HU60p_mmK",
        "outputId": "86ad3674-753f-41c9-d1c5-f8b460a7a293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'Plant-AI-Doctor': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9I0vABZ_qUw",
        "outputId": "d5c7ca33-97ae-4385-9c8e-eeea56e73393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Plant-AI-Doctor/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXf_bEY1_vNU",
        "outputId": "58f79d0b-2a0e-467d-de8c-080ec66002bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'Plant-AI-Doctor/data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Plant-AI-Doctor/data/images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z0lPz8-AA7A",
        "outputId": "62b96e41-f893-45a0-93b5-4c6bb5f0cd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'Plant-AI-Doctor/data/images': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Plant-AI-Doctor/data/images/real\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEz4AQauAFWA",
        "outputId": "f9262ba0-2d7d-4b52-ad1b-cdef82459400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'Plant-AI-Doctor/data/images/real': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "BASE = Path(\"Plant-AI-Doctor/data/images/real\")\n",
        "chem_dir = BASE / \"chemical\"\n",
        "dis_dir  = BASE / \"disease\"\n",
        "\n",
        "print(\"BASE exists:\", BASE.exists())\n",
        "print(\"chemical exists:\", chem_dir.exists())\n",
        "print(\"disease exists:\", dis_dir.exists())\n",
        "\n",
        "print(\"chemical count:\", len(list(chem_dir.iterdir())))\n",
        "print(\"disease count:\", len(list(dis_dir.iterdir())))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Te1MuxuUAH6d",
        "outputId": "14762e67-fb62-4171-c882-60caf904a8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE exists: False\n",
            "chemical exists: False\n",
            "disease exists: False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Plant-AI-Doctor/data/images/real/chemical'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2977212702.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"disease exists:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chemical count:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchem_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"disease count:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0mspecial\u001b[0m \u001b[0mentries\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'..'\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mincluded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \"\"\"\n\u001b[0;32m-> 1056\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_child_relpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Plant-AI-Doctor/data/images/real/chemical'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def list_images(folder: Path):\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
        "    return [p for p in folder.iterdir() if p.suffix.lower() in exts]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for p in list_images(chem_dir):\n",
        "    rows.append({\"filepath\": str(p), \"label\": \"chemical\", \"source\": \"real\"})\n",
        "\n",
        "for p in list_images(dis_dir):\n",
        "    rows.append({\"filepath\": str(p), \"label\": \"biological\", \"source\": \"real\"})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "print(\"Total:\", len(df))\n",
        "print(df[\"label\"].value_counts())\n",
        "df.head(5)\n"
      ],
      "metadata": {
        "id": "v4tI1OMbAR3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def split_group(df_class, train=0.7, val=0.15):\n",
        "    df_class = df_class.sample(frac=1, random_state=42)  # ערבוב\n",
        "    n = len(df_class)\n",
        "\n",
        "    train_end = int(n * train)\n",
        "    val_end = int(n * (train + val))\n",
        "\n",
        "    splits = (\n",
        "        [\"train\"] * train_end +\n",
        "        [\"val\"] * (val_end - train_end) +\n",
        "        [\"test\"] * (n - val_end)\n",
        "    )\n",
        "\n",
        "    df_class = df_class.copy()\n",
        "    df_class[\"split\"] = splits\n",
        "    return df_class\n",
        "\n",
        "df = df.groupby(\"label\", group_keys=False).apply(split_group)\n",
        "\n",
        "df[\"split\"].value_counts(), df.groupby([\"label\", \"split\"]).size()\n"
      ],
      "metadata": {
        "id": "6DzHJXzBXoU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uYKaL05pbo2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def show_samples(df, label, n=4):\n",
        "    samples = df[df[\"label\"] == label].sample(n)\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    for i, row in enumerate(samples.itertuples()):\n",
        "        img = Image.open(row.filepath)\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "    plt.suptitle(label)\n",
        "    plt.show()\n",
        "\n",
        "show_samples(df, \"chemical\")\n",
        "show_samples(df, \"biological\")"
      ],
      "metadata": {
        "id": "R6WRNjbebv-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n"
      ],
      "metadata": {
        "id": "hhf-WH7Ld46F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "iIdu_QtQghzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LeafDataset(Dataset):\n",
        "    def __init__(self, df, split, transform=None):\n",
        "        self.df = df[df[\"split\"] == split].reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row.filepath).convert(\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = 1 if row.label == \"chemical\" else 0\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "ey7D4WjIg-mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "356Uhit5hKPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = LeafDataset(df, split=\"train\", transform=image_transform)\n",
        "val_dataset   = LeafDataset(df, split=\"val\", transform=image_transform)\n",
        "test_dataset  = LeafDataset(df, split=\"test\", transform=image_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "GgQQMgtyheZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "model = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "id": "XEgssOyRipeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(model.fc.in_features, 2)"
      ],
      "metadata": {
        "id": "5u96GRQikRuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "DXg5uQoAkZqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "PgLN0C_1kpIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    return running_loss / len(loader)"
      ],
      "metadata": {
        "id": "UcXZe-fzltsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch(\n",
        "        model,\n",
        "        train_loader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        device\n",
        "    )\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Train loss: {train_loss:.4f}\")"
      ],
      "metadata": {
        "id": "qH32KC2vlv03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "X1N_QVeJl0Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc = evaluate(model, val_loader, device)\n",
        "print(f\"Validation accuracy: {val_acc:.3f}\")"
      ],
      "metadata": {
        "id": "tCInyGdbmsQJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_losses, label='Train Loss')\n",
        "plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
        "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BJ9SfBuVb-MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_dataset)"
      ],
      "metadata": {
        "id": "A8Jg_CQ1musi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths = set(train_dataset.df.filepath)\n",
        "val_paths   = set(val_dataset.df.filepath)\n",
        "\n",
        "len(train_paths.intersection(val_paths))"
      ],
      "metadata": {
        "id": "kKRBC884m94n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = evaluate(model, test_loader, device)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "wdr875u4nA89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade diffusers transformers accelerate safetensors"
      ],
      "metadata": {
        "id": "OpWoJCxKnGdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n"
      ],
      "metadata": {
        "id": "pKCT2HUe7qCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
        "OUT_DIR = \"/content/synthetic_chemical\"\n",
        "N_IMAGES = 10\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "twZm56co7uMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = (\n",
        "    \"A realistic high-resolution photo of a tomato plant leaf with chemical damage ONLY. \"\n",
        "    \"Large irregular burned areas, scorched leaf tissue, uneven yellow and brown discoloration. \"\n",
        "    \"Diffuse damage caused by herbicide or pesticide exposure. \"\n",
        "    \"Natural outdoor agricultural setting, photorealistic, sharp focus.\"\n",
        ")\n",
        "\n",
        "NEG_PROMPT = (\n",
        "    \"fungal disease, bacterial disease, leaf spot, round spots, lesions, mold, mildew, \"\n",
        "    \"watermark, text, logo, cartoon, illustration\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "oUwqZFj17v2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "    safety_checker=None\n",
        ").to(device)\n",
        "\n",
        "pipe.enable_attention_slicing()\n"
      ],
      "metadata": {
        "id": "HTHw2PMc7zLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_path = os.path.join(OUT_DIR, \"metadata.jsonl\")\n",
        "\n",
        "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i in range(1, N_IMAGES + 1):\n",
        "        seed = random.randint(0, 2**31 - 1)\n",
        "        generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "        image = pipe(\n",
        "            prompt=PROMPT,\n",
        "            negative_prompt=NEG_PROMPT,\n",
        "            num_inference_steps=30,\n",
        "            guidance_scale=7.5,\n",
        "            generator=generator\n",
        "        ).images[0]\n",
        "\n",
        "        filename = f\"chem_synth_{i:02d}.png\"\n",
        "        image.save(os.path.join(OUT_DIR, filename))\n",
        "\n",
        "        f.write(json.dumps({\n",
        "            \"file\": filename,\n",
        "            \"label\": \"chemical\",\n",
        "            \"seed\": seed,\n",
        "            \"model\": MODEL_ID\n",
        "        }) + \"\\n\")\n",
        "\n",
        "print(\"✔ Done! Images saved to:\", OUT_DIR)\n",
        "print(\"Files:\", os.listdir(OUT_DIR))\n"
      ],
      "metadata": {
        "id": "56UQblJS72ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OFI6939477VZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}